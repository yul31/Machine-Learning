{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94402c9",
   "metadata": {},
   "source": [
    "### 회귀\n",
    "#### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99a6e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a060d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([\n",
    "    [2,1],\n",
    "    [3,2],\n",
    "    [3,4],\n",
    "    [5,5],\n",
    "    [7,5],\n",
    "    [2,5],\n",
    "    [8,9],\n",
    "    [9,10],\n",
    "    [6,12],\n",
    "    [9,2],\n",
    "    [6,10],\n",
    "    [2,4]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79fcdd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08849832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_index:  [ 3  4  5  6  7  8  9 10 11]\n",
      "test_index:  [0 1 2]\n",
      "train_index:  [ 0  1  2  6  7  8  9 10 11]\n",
      "test_index:  [3 4 5]\n",
      "train_index:  [ 0  1  2  3  4  5  8  9 10 11]\n",
      "test_index:  [6 7]\n",
      "train_index:  [ 0  1  2  3  4  5  6  7 10 11]\n",
      "test_index:  [8 9]\n",
      "train_index:  [0 1 2 3 4 5 6 7 8 9]\n",
      "test_index:  [10 11]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(x_data):\n",
    "    print('train_index: ', train_index)\n",
    "    print('test_index: ', test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb199d",
   "metadata": {},
   "source": [
    "### K-Fold 교차검증 -> 보통 회귀 문제에 사용됨\n",
    "- 학습데이터와 테스트 데이터를 k개의 세트로 나누어 검증하는 방법\n",
    "- 데이터셋이 굉장히 적을 때 훈련 데이터를 어떻게든 최대한 늘려보려고 사용하는 것\n",
    "- 여러개의 훈련데이터, 테스트데이터 짝으로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4d0f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19823c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([\n",
    "    [2,1],\n",
    "    [3,2],\n",
    "    [3,4],\n",
    "    [5,5],\n",
    "    [7,5],\n",
    "    [2,5],\n",
    "    [8,9],\n",
    "    [9,10],\n",
    "    [6,12],\n",
    "    [9,2],\n",
    "    [6,10],\n",
    "    [2,4]\n",
    "])\n",
    "\n",
    "y_data = np.array([3,5,7,10,12,7,13,13,12,13,12,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "397a4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1d62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for train_index, test_index in kf.split(x_data):\n",
    "    x_train = np.array(x_data)[train_index]\n",
    "    y_train = np.array(y_data)[train_index]\n",
    "    x_test = np.array(x_data)[test_index]\n",
    "    y_test = np.array(y_data)[test_index]\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    score = lr.score(x_train, y_train)\n",
    "    train_scores.append(score)\n",
    "    \n",
    "    score_test = lr.score(x_test, y_test)\n",
    "    test_scores.append(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "863ee76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9522707858769932,\n",
       " 0.9469593697441799,\n",
       " 0.9446524178499608,\n",
       " 0.9232432525564045,\n",
       " 0.9166499001004778]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737460b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.1475590101753324,\n",
       " 0.56847222331606,\n",
       " 0.0,\n",
       " -11.7747639790487,\n",
       " 0.9602035173350366]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores #잘 예측하면 0~1 사이의 값, 잘못 예측하면 음수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27c698cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9367551452256032\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_scores).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cd0b285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.278729449714587\n"
     ]
    }
   ],
   "source": [
    "print(np.array(test_scores).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a387430",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_data, y_data)\n",
    "\n",
    "x_test = np.array([\n",
    "    [4,6]\n",
    "])\n",
    "\n",
    "y_predict = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b36610b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.27950438])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e717d393",
   "metadata": {},
   "source": [
    "### 계층별 k-겹 교차검증(Stratified k-fold cross validation)\n",
    "- 분류모델에 적용\n",
    "- k-겹 교차검증은 k-fold가 원본 데이터 집합의 레이블 분포를 학습 및 검증 데이터 세트에 제대로 분배하지 못하는 문제를 해결해주고, 레이블에 속성값을 개수를 골고루 넣어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e485e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression #회귀모델x, 선형분류o\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fccbe5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d3d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6eba75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec3af548",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf9b26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys() #참고해서 x,y값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93bda634",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a42303b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 교차 검증 정확도 : 1.0 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n",
      "2번째 교차 검증 정확도 : 0.9667 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n",
      "3번째 교차 검증 정확도 : 0.9 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n",
      "4번째 교차 검증 정확도 : 1.0 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n",
      "5번째 교차 검증 정확도 : 0.9667 \n",
      " 학습 데이터 크기 : 120 \n",
      " 검증 데이터 크기 : 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "idx_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, test_index in skf.split(x, y) :\n",
    "    \n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    lr.fit(x_train, y_train)\n",
    "    pred = lr.predict(x_test)\n",
    "    \n",
    "    idx_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = x_train.shape[0] #0번째 데이터 : 행의 개수\n",
    "    test_size = x_test.shape[0]\n",
    "    \n",
    "    print('{0}번째 교차 검증 정확도 : {1} \\n 학습 데이터 크기 : {2} \\n 검증 데이터 크기 : {3}'.format(idx_iter, accuracy, train_size, test_size))\n",
    "    \n",
    "    cv_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a9326b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape #행의 개수 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de204b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 : [1.     0.9667 0.9    1.     0.9667]\n",
      "평균 검증 정확도 : 0.96668\n"
     ]
    }
   ],
   "source": [
    "print('교차 검증별 정확도 :', np.round(cv_accuracy, 4)) #소수넷째자리까지\n",
    "print('평균 검증 정확도 :', np.mean(cv_accuracy))\n",
    "# 순서대로 100%, 96%, 90%, 100%, 96%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f026b",
   "metadata": {},
   "source": [
    "<교차 검증의 장점>\n",
    "1. test set에 데이터가 최소 한 번씩 들어가기 때문에 모델이 더 잘 일반화 됨\n",
    "2. 분할을 한 번 했을 때보다 데이터를 더 효과적으로 사용해서 더 정확한 모델을 만들 수 있다\n",
    "\n",
    "<교차 검증의 단점>\n",
    "1. 연산 비용이 늘어남(k개의 모델을 만들어야 하므로 데이터를 한 번 나눴을때에 비해서 느리다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04932a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
